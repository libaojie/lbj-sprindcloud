server:
  port: 16001
spring:
  application:
    name: lbj-client-kafka-provider
#  #热部署生效
#  devtools:
#    restart:
#      enabled: true
#      #设置重启的目录,添加那个目录的文件需要restart
#      additional-paths: src/main/java
#  # 声明生效的配置文件
#  profiles:
#    # 正式环境
#    active: pro

  # Kafka配置
#  cloud:
#    stream:
#      kafka:
#        binder:
#          brokers:  192.168.160.165:19092  # kafka服务地址和端口
#          zk-nodes: 192.168.160.165:12181  # ZK的集群配置地址和端口
#          auto-create-topics: true # 如果设置为false,就不会自动创建Topic 有可能你Topic还没创建就直接调用了。
#      bindings:
#        output:      #这里用stream给我们提供的默认output，后面会讲到自定义output
#          destination: stream-demo    #消息发往的目的地
#          content-type: text/plain    #消息发送的格式，接收端不用指定格式，但是发送端要
  cloud:
    stream:
      default-binder: kafka #默认的绑定器，
      kafka: #如果用的是rabbitMQ这里填 rabbit
        binder:
          brokers: #Kafka的消息中间件服务器地址
            - 192.168.160.165:19092
      bindings:
        output: #通道名称
          binder: kafka
          destination: test1 #消息发往的目的地，对应topic
          group: output-group-1 #对应kafka的group
          content-type: text/plain #消息的格式

# 配置日志级别
logging:
  level:
    #    root: info
    root: debug
  file: ./data/log/${spring.application.name}.log







